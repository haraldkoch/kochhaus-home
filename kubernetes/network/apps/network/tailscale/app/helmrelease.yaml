---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app tailscale
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 3.6.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  values:
    controllers:
      tailscale:
        replicas: 2
        strategy: RollingUpdate
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          app:
            image:
              repository: ghcr.io/tailscale/tailscale
              tag: v1.80.0@sha256:27b6a3dc30d89e94113b0d481dae05f08934cf80bdce860041727a2a60959921
            env:
              TZ: ${TIMEZONE}
              NO_AUTOUPDATE: true
              PORT: &port ${TAILNET_PUBLIC_PORT:=1}
              TS_EXTRA_ARGS: --advertise-exit-node  --advertise-tags=tag:k8s
              TS_HOSTNAME:
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              TS_ROUTES: ${KUBERNETES_CIDR},${HOMELAN_IPV4}
              TS_STATE_DIR: &path /tmp
              TS_TAILSCALED_EXTRA_ARGS: --debug=0.0.0.0:9001
              TS_USERSPACE: true
            envFrom:
              - secretRef:
                  name: tailscale-secret
            probes:
              liveness: &probe
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /debug/pprof/
                    port: 9001
                  initialDelaySeconds: 15
                  periodSeconds: 20
                  timeoutSeconds: 1
                  failureThreshold: 3
              readiness: *probe
            resources:
              requests:
                cpu: 10m
              limits:
                memory: 256Mi
            securityContext:
              allowPrivilegeEscalation: false
              readOnlyRootFilesystem: true
              capabilities:
                drop:
                  - ALL
    defaultPodOptions:
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      securityContext:
        runAsNonRoot: true
        runAsUser: 568
        runAsGroup: 568
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: *app
    persistence:
      cache:
        type: emptyDir
        globalMounts:
          - path: /.cache
      tmp:
        type: emptyDir
        globalMounts:
          - path: *path
      run:
        type: emptyDir
        globalMounts:
          - path: /var/run
    service:
      app:
        controller: *app
        nameOverride: *app
        ports:
          http:
            port: 9001
      tailnet:
        controller: *app
        type: LoadBalancer
        externalIPs: ["${TAILSCALE_IPV4}", "${TAILSCALE_IPV6}"]
        externalTrafficPolicy: Local
        ipFamilyPolicy: PreferDualStack
        ipFamilies: [IPv4, IPv6]
        ports:
          tailnet:
            port: *port
            protocol: UDP
    serviceMonitor:
      app:
        serviceName: *app
        endpoints:
          - port: http
            scheme: http
            path: /debug/metrics
            interval: 1m
            scrapeTimeout: 10s
