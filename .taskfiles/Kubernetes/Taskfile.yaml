---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

tasks:

  browse-pvc:
    desc: Browse PersistentVolumeClaims
    summary: |
      Args:
        cluster: Cluster to run command against (required)
        ns: Namespace to browse PersistentVolumeClaims in (default: default)
        claim: PersistentVolumeClaim to browse (required)
    interactive: true
    cmd: |
      kubectl --context {{.cluster}} run -n {{.ns}} debug-{{.claim}} -i --tty --rm --image=null --privileged --overrides='
        {
          "apiVersion": "v1",
          "spec": {
            "containers": [
              {
                "name": "debug",
                "image": "ghcr.io/haraldkoch/ubuntu:rolling",
                "command": ["/bin/bash"],
                "stdin": true,
                "stdinOnce": true,
                "tty": true,
                "volumeMounts": [
                  {
                    "name": "config",
                    "mountPath": "/config"
                  }
                ]
              }
            ],
            "volumes": [
              {
                "name": "config",
                "persistentVolumeClaim": {
                  "claimName": "{{.claim}}"
                }
              }
            ],
            "restartPolicy": "Never"
          }
        }'
    vars:
      ns: '{{.ns | default "default"}}'
    requires:
      vars: ["cluster", "claim"]
    preconditions:
      - kubectl --context {{.cluster}} --namespace {{.ns}} get persistentvolumeclaims {{.claim}}
      - kubectl browse-pvc --version
      - which kubectl

  node-shell:
    desc: Open a shell to a node [CLUSTER=main] [NODE=required]
    interactive: true
    cmd: kubectl node-shell --context {{.CLUSTER}} -n kube-system -x {{.NODE}}
    requires:
      vars: [CLUSTER,NODE]
    preconditions:
      - kubectl get nodes --context {{.CLUSTER}} {{.NODE}}
      - kubectl node-shell --version
      - which kubectl

  sync-secrets:
    desc: Sync all ExternalSecrets
    cmds:
      - for: { var: SECRETS, split: "\n" }
        cmd: kubectl --context {{.CLUSTER}} --namespace {{splitList "," .ITEM | first}} annotate externalsecret {{splitList "," .ITEM | last}} force-sync="{{now | unixEpoch}}" --overwrite
    vars:
      SECRETS:
        sh: kubectl get externalsecret --context {{.CLUSTER}} --all-namespaces --no-headers --output=jsonpath='{range .items[*]}{.metadata.namespace},{.metadata.name}{"\n"}{end}'
    requires:
      vars: [CLUSTER]
    preconditions:
      - which kubectl

  cleanse-pods:
    desc: Cleanse pods with a Failed/Pending/Succeeded phase
    cmds:
      - for:
          matrix:
            PHASE: [Failed, Pending, Succeeded]
        cmd: kubectl delete pods --context {{.CLUSTER}} --all-namespaces --field-selector status.phase={{.ITEM.PHASE}} --ignore-not-found=true
    requires:
      vars: [CLUSTER]
    preconditions:
      - which kubectl

  drain:
    desc: Drain a node
    summary: |
      Args:
        cluster: Cluster to run command against (required)
        node: Node to drain (required)
    cmd: kubectl --context {{.cluster}} drain {{.node}} --ignore-daemonsets --delete-local-data --force
    requires:
      vars: ["cluster", "node"]

  network:
    desc: Create a netshoot container for a cluster
    summary: |
      Args:
        cluster: Cluster to run command against (required)
        ns: Namespace the PVC is in (default: default)
    interactive: true
    requires:
      vars: ["cluster"]
    cmd: |
      kubectl run --context {{.cluster}} -n {{.ns}} netshoot --rm -i --tty --image ghcr.io/nicolaka/netshoot:latest {{.CLI_ARGS}}
    vars:
      ns: '{{.ns | default "default"}}'

  list-dockerhub:
    desc: What dockerhub images are running in my cluster
    summary: |
      Args:
        cluster: Cluster to run command against (required)
    interactive: true
    cmd: |
      kubectl --context {{.cluster}} get pods --all-namespaces -o=jsonpath="{range .items[*]}{'\n'}{range .spec.containers[*]}{.image}{'\n'}{end}{end}" | sort | uniq | grep -Ev 'quay|gcr|ghcr|ecr|us-docker|registry.k8s' | grep -Ev 'bitnami|rook|intel|grafana' |  sed -e 's/docker\.io\///g' | sort | uniq
    requires:
      vars: ["cluster"]

  hash-secret:
    desc: Hash a client secret (for Authelia)
    interactive: true
    cmd: podman run --rm -ti authelia/authelia:latest authelia crypto hash generate pbkdf2 --variant sha512


  # https://docs.github.com/en/enterprise-cloud@latest/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller#upgrading-arc
  upgrade-arc:
    desc: Upgrade the ARC
    cmds:
      - helm -n actions-runner-system uninstall home-ops-runner
      - helm -n actions-runner-system uninstall actions-runner-controller
      - sleep 5
      - flux -n actions-runner-system reconcile hr actions-runner-controller
      - flux -n actions-runner-system reconcile hr home-ops-runner
    preconditions:
      - which flux helm

